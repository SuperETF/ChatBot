import { openai } from "../services/openai.js";

export default async function classifyIntent(utterance) {
  const prompt = `
ë‹¤ìŒ ì‚¬ìš©ì ë°œí™”ë¥¼ ì•„ë˜ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ë¡œ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

- ìš´ë™ ì˜ˆì•½
- ë£¨í‹´ ì¶”ì²œ
- ì‹ë‹¨ ì¶”ì²œ
- ì‹¬ë°•ìˆ˜ ì…ë ¥
- ë‚´ ì •ë³´ ì¡°íšŒ
- íšŒì› ë“±ë¡
- ê¸°íƒ€

ğŸ“Œ ê·œì¹™:
- ì „í™”ë²ˆí˜¸(010ìœ¼ë¡œ ì‹œì‘)ê°€ í¬í•¨ë˜ë©´ ë¬´ì¡°ê±´ "íšŒì› ë“±ë¡"
- ì´ë¦„ + ì „í™”ë²ˆí˜¸ ì¡°í•©ì´ë©´ "íšŒì› ë“±ë¡"
- "ë‚´ ì •ë³´" ê´€ë ¨ ë°œí™”ëŠ” "ë‚´ ì •ë³´ ì¡°íšŒ"
- ìœ„ ì™¸ì—ëŠ” ì˜ë¯¸ì— ë”°ë¼ íŒë‹¨

ë¬¸ì¥: "${utterance}"
ë‹µë³€:
`;

  const response = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: prompt }],
    temperature: 0
  });

  return response.choices[0].message.content.trim();
}
